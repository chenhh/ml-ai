# 簡介

## 簡介

統計學中，只有討論相關性\(correlation\)與總結資料，不討論因果關係\(casualty\)。此觀念影響學界長期研究關聯，而不研究因果。

1980年初，Pearl認為「不確定性」是AI所缺乏的最重要能力，因此發明了貝式網路\(Baye's network\)。1980年末，Pearl認為貝式網路沒有辦法彌補人工智慧和人類知能的差距，因此開始研究因果關係。1980年末，Pearl研究發現「機器無法理解因果關係」可能是它們無法具備\(強\)人工智能的主要原因。語言會形塑思想。我們無法解答自已無法提出的問題，也無法提出無法描述的問題。Pearl在Casualty這本書將因果關係數學化。

因果推論相關常見的語句有：「預防」、「使得」、「歸因於 」、「政策」。現在都可用數學化的方式處理。

Francis Galton與Karl Pearson在統計學中，均不處理因果關係，「相關不是因果關係」\(correlation is not causation\)。因為因果關係和科學使用的單詞有基本上的差異。 

* 如氣壓計讀數為$$B$$時，代表大氣壓力為$$P$$，可得關係式$$B=kP$$。然後可再改寫為$$P=\frac{B}{k}$$、$$k=\frac{B}{P}$$、$$B-kP=0$$等。這些式子中，只要知道兩個變量，就可以求出第三個變量。但無法表達出壓力如何造成氣壓計讀數改變，而不是氣壓計造成壓力改變。
* 撥動開關可以關燈或開燈。
* 天氣熱時，冰店生意會好。

單純的資料，不論資料量有多少，都只能得到相關關係，無法得到因果關係。比如「抽菸是否危害健康？」，「阿斯匹靈是否對頭痛有效？」

1920年，Sewall G. Wright發明路徑分析\(path analysis\)為因果分析的始祖方法。

**因果微積分：不需實際介入，就能預測介入的效果**。但必須定義do運算符號以及找出非侵入性方式模擬介入。

* 因果圖\(causal diagram\)，用來描述已知事物。
  * 簡單的點與箭頭圖，點為變項\(variable\)，箭頭代表變項間已知或可能的因果關係。
* 符號式的查詢語言

  * $$P(L | do(D))$$：想知道某種藥物$$D$$對壽命$$L$$的影響。如果讓一位患者服用這種藥物，則存活$$L$$年的機率$$P$$為何？$$do(D)$$表示介入或治療，而非被動觀察。
  * 有時還會比較$$P(L|do(D))$$與$$P(L|do(not \ D))$$，前面為實驗組，後面是對照組。
  * 使用$$do(D)$$確定壽命$$L$$的變化來自於藥物本身，而不是其它因素的干擾。
  * $$P(L|D)$$指自願服用藥物的患者的預期壽命$$L$$，而$$D$$是指觀察到患者服藥\(非主動介入\)。$$do(D)$$是要求患者服藥\(主動介入\)。

必須要清楚區別「觀察到某個現象」和「刻意造成此現象\(do\)」，否則會造成矛盾。如：

* 為了降低生病的機率而不去看醫生。
* 為了減少火災而裁撤消防隊。

如果探討的主題必須回顧過去時，會使用**「反事實」\(counterfactual\)**的方式。如果病人服用了$$D$$藥物後死亡，則要假設如果病人在服用藥物時改變主意，那他會不會活下來？反事實探討的是「如果...會怎樣？」。實際觀察結果永遠無法證實或反駁這類問題的答案。不過對於可能發生或可能已經發生的狀況，這類思想可以做出非常正常、可以重現的判斷。



## 因果的三個層級

因果學習者至少必須掌握三個層級的認知能力：

1. **觀看與觀察**，以探知環境中的規律。
2. **實行**，即預測刻意改變環境的效果，並選擇適當的改變以獲得想要的結果。
3. **想像**，因果階梯的三個層級：「觀察」、「介入」、「反事實」是由此而來，可證明每一層都具備前一層所缺少的能力。

## 干擾與去干擾\(去除潛在變項\)

隨機對照實驗\(RCT\)是統計學對因果推論的重大貢獻。它的主要目標是將要探討的的變項與可能影響它的其它變項分開。**去除這些潛在變項造成的干擾，需要的不是統計方法，而是因果方法**。

## 悖論\(paradox\)

這些悖論幾乎都和因果直覺抵觸。

* Monty Hall 問題，三門問題，山羊問題。
* Simpson悖論。
* Berkson悖論。

## 因果推論模型

![&#x56E0;&#x679C;&#x63A8;&#x8AD6;&#x5F15;&#x64CE;](../.gitbook/assets/inference_engine-min%20%281%29.png)

推論引擎可接受三種輸入：假設、查詢、資料。

第一種輸出為「是/否」，說明我們提出的查詢理論上是否可在資料沒有缺陷和限制的前提下，依據現有的因果模型解答。如果答案為「是」，則引擎產生「被估量」\(estimated\)，其為數學公式，可想成可取得任何假設資料產生答案的方法。而在取得資料後，會以這個方法產生求取答案所需的實際被估量。以及這次估算中的不確定性的統計估計量。這個不確定性反映出資料的有限大小，以及可能的測量誤差或缺少的資料。

例：藥物$$D$$對壽命$$L$$的影響。

1. **「知識」是推理者本身具備與此查詢有關的過往經驗，包括以往的觀察結果、以往的行動、教育和文化習慣等**。「知識」周圍的虛線代表它隱藏在推理者的思想中，模型不會明確說明。
2. 科學研究一定需要簡化假設，也就是研究者認為需要依據現有知識清楚說明的的敘述。研究者的知識大多藏在腦中，只有假設有機會見到天日，納入模型。
3. 因果模型有許多形式，因果圖、結構方程式、邏輯敘述等。最簡便的是因果圖。如在因果圖中由$$D$$指向$$L$$表示$$D$$為$$L$$的原因，表示患者的壽命$$L$$可能與是否服用藥物$$D$$有關。也有可能受到其它原因$$Z$$的影響。
4. **以因果模型路徑呈現的聽從型態，通常會在資料中形成觀察得到的型態或相依性\(dependency\)**。這些型態可用於檢驗模型的正確性，因此稱為**可驗證含意\(testable implication\)**。如「$$D$$和$$L$$沒有路徑連結」可改寫為「$$D$$和$$L$$統計獨立」。如果資料和這個含意不符，則必須使用資料和假設修改模型\(的參數\)，以增加配適程度。
5. 送進推論引擎的查詢，是想要解答的科學問題，必須以因果詞彙寫成式子。例$$P(L| do(D))$$。
6. 被估量是以資料估計的統計量，估計完成後即可回答查詢。被估量通常寫成機率公式的形式，如$$P(L|D,Z) \times P(Z)$$，但其實是依據現有資料種類解答因果查詢的方法，前提是資料種類必須經過引擎檢定。但仍有部份查詢無法處理。例：模型指出$$D$$和$$L$$都與第三個變數$$Z$$有關\(疾病的病程\)，而且$$Z$$無法測定，則無法解答$$P(L|do(D))$$。應更改模型或是新增資識以估計$$Z$$，或是簡化假設$$Z$$的$$D$$的影響可忽略。
7. 資料無法得出因果關係\(一定要以模型做假設修正\)。資料告訴我們$$P(L|D)$$或$$P(L|D,Z)$$這類查詢量，被估量負責將這些統計量轉成表達式，而依據模型的假設，這個表達式等同於因果查詢$$P(L|do(D))$$。
8. 結果為估計值，但只是近似值。
9. 如果模型正確，資料也充足，可得因果查詢的答案。例$$D$$藥物可使糖尿病患者$$Z$$的壽命延長30%，誤差為20%。

**搜集資料的時間，一定是在確定因果模型\(不一定完全正確\)，提出想解答的科學查詢，以及確定被估量之後。與傳統統計學剛好相反**。

現在許多AI或ML的研究中，常想跳過因果模型建構的步驟，直接以資料處理所有認知工作。**但是資料無法表達原因與結果間的關係。例如說，除非是可控的實驗下所搜集的資料，原始的資料一般沒有資訊說明活動或介入造成的影響**。而如果有因果模型，則可由客觀資料，預測介入的結果。

因果模型的另一個優點就是\(在不同環境\)的適應能力，因為因果結構不變，因此估計的結果仍然有效，不必像ML重新調參數。例如說患者服用藥物$$D$$的結果$$L$$，可預測具有特質$$Z$$的某患者存活$$L$$年的機率。而即使在不同的地區，人口特質不同，但是因為因果結構不變，因果模型仍然有效，很容易產生新的估計量。





## 參考資料

* Judea Pearl, and Dana Mackenzie. The book of why: the new science of cause and effect. Basic books, 2018.
  * \[中文版\] 因果革命:人工智慧的大未來, 大牌出版 遠足文化發行, 2019.
* [Judea Pearl, Causality, Cambridge university press, 2009](http://bayes.cs.ucla.edu/BOOK-2K/).



