# 資訊測度

## 訊息量\(資訊熵\)

當我們觀測到或聽到一個事件發生時，就得到了一些「訊息」。「訊息量」指的是：該訊息的內涵多寡，也可以這麼說：「訊息」的內涵是用來表達某事件之各種可能結果可能性大小。

**當事件越明確時，關於此事件所能訊息量越小。**而當事件越模糊\(機率接近0.5或1/n，均勻分配\)時，提供一件可供判斷的參考就含有較多的訊息。 當機率越平均時，也就是個事件發生機率越均勻\(即越無法預測，也越模糊\)，「不確定性」\(uncertainty\)最高，此時訊息熵最大。

故「訊息」可以視為「不確定性」或「訊息選擇的自由度」之度量。\(Information is a measure of one's freedom of choice when one selects a message\)一條資訊的信息量大小和它的不確定性有直接的關係。

比如說，我們要了解一件非常非常不確定的事，或是我們一無所知的事情，就需要瞭解大量的資訊。相反，如果我們對某件事已經有了較多的瞭解，我們不需要太多的資訊就能把它搞清楚。所以，從這個角度來說，我們可以將不確定性\(自由度\)的多寡做為信息量的度量。簡單的說，**變數的不確定性越大，熵也就越大**。







