# Bias-Variance Tradeoff

## 問題簡介

* 過度擬合\(Overfitting\)：找出來的模型受到訓練資料的影響太大，使得對預測的效果不佳。可由訓練集的低誤差與測試集的高誤差中觀察得到。
* 低度\(欠\)擬合\(Underfitting\)：模型對於資料的描述能力太差，無法正確解釋資料。可由訓練集與測試集均為高誤差觀察得到。

偏差\(Bias\)就是我們模型的準度，我們希望模型越準越好，也就是希望Bias降很低，但此時我們又會遇到另一個問題，要是模型針對我們訓練集資料學得很好，就會降低對其他資料的準度，也就是變異\(Variance\)會提高，所以我們在做的是一個取捨，用過度擬合與低度擬合的角度來看的話：

* 過度擬合：試圖去降低偏差，到最後偏差變很小，然而變異卻提高許多。
* 低度擬合：偏差很高，準度不足。

低偏差的模型在訓練集合上更加準確，低變異的模型在不同的訓練集合上性能更加穩定。舉兩個極端的例子：

* 記住訓練集合上所有資料的答案\(類別\)，這樣的系統是低偏差、高變異。
* 無論輸入什麼資料，總是預測一個相同的答案\(類別\)，這樣的系統是高偏差、低變異。

因此在模型的選擇上需要進行偏差和變異的權衡。



![&#x504F;&#x5DEE;&#x8207;&#x8B8A;&#x7570;&#x6578;&#x7684;&#x5F71;&#x97FF;](../.gitbook/assets/bias-and-variance_orig-min.png)

顯然複雜的模型能更好的擬合訓練集合能更好的擬合訓練集合上的點，但是同時高複雜度的模型泛化能力差，造成了高變異。

下圖中橫坐標的右側是過度擬合的情況，而左側是低度擬合的情況。過度擬合可以這麼解釋：

* 訓練樣本得到的輸出和其期望的輸出總誤差很小，但是測試樣本得到的輸出和其期望的輸出誤差卻很大。
* 因此為了得到一致的輸出誤差，使得模型變得相當複雜。

想像某個學習算法產生了一個過度擬合的分類器，這個分類器能夠百分之百正確地分類樣本資料，但也就為了能夠對樣本完全正確的分類，使得它的構造如此複雜，規則如此嚴格，以至於任何與樣本數據稍有不同的資料它全都認為不屬於這個類別\(低泛化能力\)。

隨著模型複雜度的增加，偏差會越來越低；而變異數卻呈現了越來越高的趨勢，兩者之值是反向的，只有在模型複雜度適中的時候，才有辦法得到最低的總誤差。



如果這部分一樣把 模型的複雜度 與 模型預測的誤差 畫成圖表的話，



![&#x6A21;&#x578B;&#x8907;&#x96DC;&#x5EA6;&#x5C0D;&#x9810;&#x6E2C;&#x80FD;&#x529B;&#x7684;&#x5F71;&#x97FF;](../.gitbook/assets/bias-variance-tradeoff-min.png)

那可能有人會想說，既然如此，能得到最佳總誤差的點會落在總誤差函數的轉折點，而總誤差又是從偏差跟 變異數而來，應該能寫出一個數學式子來找出那個最佳模型複雜度是多少。理論上是這麼說沒錯，不過在實務上有時候我們可能會很難去計算模型的偏差與變異數。

所以在實務上我們更常透過模型外在的表現來判斷它現在是低度還是過度擬合，再透過調整模型的超參數\( Hyperparameter \) 來調整模型的複雜度。實際操作上，一般我們會將資料集切割成訓練集\(training set\)跟 驗證集\(validation set\)，訓練集用於訓練模型參數；而驗證集將不會參與訓練，用於評估模型是否過度擬合。

下圖可以觀察到：

* 在低度擬合的時候，不論是在訓練集還是驗證集\(測試集\)的誤差都很高。
* 在過度擬合的時候，訓練集的誤差已經將降低了，但驗證集\(測試集\)上的誤差會很高。

​有了這兩個重要的觀察，在訓練的時候我們就可以很容易的判斷模型擬合資料的好壞。

![&#x6A21;&#x578B;&#x8907;&#x96DC;&#x5EA6;&#x5C0D;&#x9810;&#x6E2C;&#x504F;&#x5DEE;-&#x8B8A;&#x7570;&#x6578;&#x7684;&#x5F71;&#x97FF;](../.gitbook/assets/bias-variance-tradeoff.jpg)

## 訓練誤差與測試誤差

![&#x904E;&#x5EA6;&#x8207;&#x4F4E;&#x5EA6;&#x64EC;&#x5408;&#x65BC;&#x6A21;&#x578B;&#x9810;&#x6E2C;&#x7684;&#x7D50;&#x679C;](../.gitbook/assets/over-under-fitting-min.png)

### 低度擬合

當訓練一個模型時，**若發現不論是在訓練集或是測試集資料都無法達到一定的準度時，就可能是遇到低度擬合的狀況**。通常造成低度擬合的主要原因包含『訓練時間不足』、『模型複雜度不足』，而這兩種狀況都不難解決。可以透過增加訓練迭代的次數來解決「訓練時間不足」的問題，透過調整參數數量來解決「模型複雜度不足」的問題。如果上述調整仍然無法改善，可能就要考慮是訓練資料本身的問題。

### 過度擬合

當隨個訓練的時間增長、迭代的次數增加，我們訓練集與測試集的誤差都會逐步的下降，但當我們觀察到訓練集與測試集的誤差開始分道揚鑣時，就可能是過度擬合狀況發生。

**用一句話描述過度擬合：模型過度去學習、硬背訓練資料**。



### 總結

低度擬合：發生低度擬合的根本原因是由於模型太過簡單，所以根本的解決方案就是提高模型的複雜度，可以透過：

* 增加訓練的疊代次數
* 調整超參數 \( 修改模型架構 \)
* 生成更多的特徵來訓練模型
* 如果有使用正規化 \( Regularization \) 可先將其移除
* 更換一個更複雜的模型

過度擬合：發生過度擬合的根本原因是由於模型太過複雜，所以根本的解決方案就是降低模型的複雜度，可以透過：

* Early Stopping
* 增加訓練資料
* 降低特徵維度
* 如果沒有使用正規化 \( Regularization \) 可以將其加入
* 調整超參數 \( 修改模型架構 \)
* 更換一個較為簡單的模型​

