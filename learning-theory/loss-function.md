# 損失函數\(loss function\)

## 簡介

沒有一個損失函數可以適用於所有類型的資料。損失函數的選擇取決於許多因素，包括是否有離群點，機器學習演演算法的選擇，運行梯度下降的時間效率，是否易於找到函數的導數，以及預測結果的信賴區間。

機器學習中的所有演算法都依賴於最小化或最大化某一個函數，我們稱之為「目標函數」\(objective function\)。最小化的這組函數被稱為「損失函數」。損失函數是衡量預測模型預測期望結果表現的指標。尋找函數最小值的最常用方法是「梯度下降」\(gradient descent\)。把損失函數想像成起伏的山脈，梯度下降就像從山頂滑下，目的是到達山脈的最低點。



損失函數可以大致分為兩類：分類損失（Classification Loss）和迴歸損失（Regression Loss）。

![&#x8FF4;&#x6B78;&#x51FD;&#x6578;&#x9810;&#x6E2C;&#x5BE6;&#x6578;&#x503C;&#xFF0C;&#x5206;&#x985E;&#x51FD;&#x6578;&#x9810;&#x6E2C;&#x6A19;&#x7C3D;\(&#x985E;&#x5225;\)](../.gitbook/assets/loss_function-min.png)

## 均方誤差，二次損失，L2 損失 \(Mean Square Error, Quadratic Loss, L2 Loss\)

均方誤差（MSE）是最常用的回歸損失函數。MSE 是目標變量與預測值之間距離平方之和。

$$
MSE =\frac{1}{N} \sum_{i=1}^{N}(y_i -\hat{y}_i)^2
$$

![MSE&#x70BA;&#x4E8C;&#x6B21;&#x51FD;&#x6578;&#xFF0C;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x5BB9;&#x6613;&#x627E;&#x5230;&#x6975;&#x5C0F;&#x503C;](../.gitbook/assets/mse-min.png)

## 平均絕對誤差，L1損失\(Mean Absolute Error, L1 Loss\)

平均絕對誤差（MAE）是另一種用於回歸模型的損失函數。MAE是目標變量和預測變量之間差異絕對值之和。因此，它在一組預測中衡量誤差的平均大小，而不考慮誤差的方向。損失范圍也是 0 到 $$\infty$$。

$$
MAE=\frac{1}{N} \sum_{i=1}^N | y_i - \hat{y}_i|
$$

![MAE&#x5728;&#x6975;&#x5C0F;&#x503C;&#x8655;&#x70BA;&#x5C16;&#x9EDE;](../.gitbook/assets/mae-min.png)

### MSE vs MAE （L2損失 vs L1損失）

使用平方誤差更容易求解，但使用絕對誤差對離群點更加穩健。每當我們訓練機器學習模型時，我們的目標就是找到最小化損失函數的點。當然，當預測值正好等於真實值時，這兩個損失函數都達到最小值。

由於 MSE 對誤差進行平方加權，如果誤差較大時，誤差的值會增加很多。如果我們的數據中有一個離群點，誤差的平方值會遠遠大於絕對值。這將使得和以 MAE 為損失的模型相比，以 MSE 為損失的模型會賦予更高的權重給離群點。因此MSE會犧牲其他正常數據點的預測效果為代價，這最終會降低模型的整體效能。

* **MAE  損失適用於訓練數據被離群點損壞的時候（即，在訓練數據而非測試數據中，我們錯誤地獲得了不切實際的過大正值或負值）**。





