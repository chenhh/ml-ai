# PAC (Probability Approximately Correct)學習理論

## 簡介

學習是希望從舊有的經驗中找尋規則，並在面對沒有看過的資料時也能成功預測。

現在問題來了，要怎麼能夠說這個模型「學得好」了呢？是要要求它「每次」都能「零錯誤率」？這樣似乎太嚴苛了。但是多少的錯誤率是可以接受的呢？又一定要每次都對嗎？還是大部分時候是對的就好？還有「尋找使得訓練錯誤率最低的函數」﹝ERM﹞這個方法什麼時候會是不錯的方法呢？

## 同態獨立分佈(Independently and Identically Distributed (i.i.d))

首先，機器學習中，能掌握的只有訓練錯誤率，因此當然希望我們手上的訓練資料越具普遍性越好。

為了達成這個目的，我們通常假設每一組訓練資料是獨立的從相同分佈中被選出來，即「同態獨立分佈」 (i.i.d.)。而如果訓練資料越多，也就越能夠反應出資料的真實機率分佈。如果說訓練資料$$S$$ 總共有$$m$$ 筆資料，而它們全部都是從$$D$$ 這個分布 i.i.d. 選出來的，那我們寫成$$S \sim D^m$$。

再來，先設想簡單的情況：假設我們所使用的機器學習方法，其選到的Hypothesis set $$H$$ 有包含目標函數$$f$$，也就是$$h^{*}(=f)$$會在 $$H$$ 裡面。

因此可在訓練後，使得真實錯誤率為0 ，即$$L_{D}(h^{*},f)=P_{x \sim D}(h^{*}(x) \neq f(x)) = 0$$。

同理可得$$h^{'} \in H$$使得訓練錯誤率為0，即$$L_S(h^{'}, f)=\frac{1}{m} \sum_{i=1}^m \mathbb{I}(h^{'}(x_i) \neq f(x_i)) =0$$。

## Probably Approximately Correct

由於訓練資料是 i.i.d. 選出來的，意味著仍有可能取到不具代表性的資料集合。為了配合機率的因素，再定義兩個參數：『信心指數』還有『正確指數』：

* 信心指數(confidence parameter):$$1-\delta$$ 。
* 正確指數(accuracy parameter): $$\epsilon$$。

如果現在$$P( [ X<\epsilon ] )>(1-\delta )$$，表示有大於$$(1-\delta )$$ 的機率 $$X$$ 會小於$$\epsilon$$ ；而$$\epsilon$$ 通常用來描述誤差的程度。

為什麼我們要討論誤差？誤差哪裡來的？別我們最後獲得的理想函數，都是經由觀察訓練資料 $$S$$ 並從 $$H$$ 中選出來的，這個理想函數現在把它寫成 $$h_S$$。無論$$h_S$$  是由什麼樣的演算法選出來的，它一定會跟 $$S$$ 有關係；之前說為了要讓 $$S$$ 具有普遍性，$$S$$ 是從某個分佈 $$D$$ 中 i.i.d.地選出來的。而很可能會有一些機率，我們的訓練資料很不幸的不具代表性，也就是跟實際分佈情形差得很遠，而導致雖然那個演算法在 $$S$$ 上雖然學得很好，但是學出來的函數其實有很大的偏差。

例如：我們想在某間水果攤買水果，老闆人很好提供試吃，但很不幸的被我們吃到的那幾塊都不好吃，藉著這個經驗我們判斷：這間水果攤的水果不好吃。但是其實實際上這裡不好吃的水果佔的比例只有20%，只是很剛好地都被選到了，這樣就造成了「誤判」。而「誤判」將會影響到我們的學習成果。

因為有資料選不好而「誤判」的可能，應該很難達成「每次」都「零失誤」的學習。那只好退而求其次了，既然不能每次都零失誤，那我們要求大部分的時候﹝Probably, $$\delta$$﹞失誤率很小，也就是很接近正確的﹝Approximately Correct, $$\epsilon$$﹞就好。因此稱為PAC learnability，只要能達成給定的一些標準，我們就說這模型表現的還不錯。



## 參考資料

* [Probably Approximately Correct — a Formal Theory of Learning](https://jeremykun.com/2014/01/02/probably-approximately-correct-a-formal-theory-of-learning/)
* [機器學習可行嗎(2)–PAC learnable](https://angnotes.wordpress.com/2017/02/14/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%8F%AF%E8%A1%8C%E5%97%8E2-pac-learnable/)
