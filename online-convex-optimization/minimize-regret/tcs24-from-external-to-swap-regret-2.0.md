# TCS24: From External to Swap Regret 2.0

## 摘要

我們提供了一種從交換遺憾最小化到外部遺憾最小化的**新穎歸約方法**，該方法**改進了** Blum-Mansour \[BM07] 和 Stolz-Lugosi \[SL05] 的經典歸約，因為它**不需要動作空間的有限性**。我們證明，只要對於某個假設類存在無外部遺憾演算法，那麼對於**相同的類**，也必然存在無交換遺憾演算法。對於使用專家建議的學習問題，我們的結果表明，有可能保證在 log(N)O(1/ϵ) 輪次後，交換遺憾被限制在 {\epsilon} 之內，且每次迭代的複雜度為 O(N)，而 Blum-Mansour 和 Stolz-Lugosi 的經典歸約則需要 O(N/ϵ2) 輪次和至少 Ω(N2) 的每次迭代複雜度。我們的結果伴隨著一個**相關的下界**，與 \[BM07] 中的下界形成對比，我們的下界對於**無意識的**（oblivious）和 **ℓ1-約束的** 對手和學習者均成立，這些學習者可以使用專家上的分佈，表明輪次數量必須是 Ω\~(N/ϵ2) 或在 1/ϵ 中呈指數級增長。

我們的歸約意味著，如果在某些賽局中可以進行無遺憾學習，那麼這個賽局必然存在**任意良好近似程度的近似相關均衡**。 這**加強了**無遺憾學習的民間共識性推論，即近似粗略相關均衡的存在性。重要的是，它為相關均衡的存在性提供了一個**充分條件**，該條件**極大地擴展了**動作集有限性的要求，從而回答了 \[DG22; Ass+23] 提出的一個懸而未決的問題。此外，它還**解答了關於均衡計算和賽局學習的幾個突出的問題**。

## 參考資料

Yuval Dagan et al. "From External to Swap Regret 2.0: An Efficient Reduction for Large Action Spaces," Proceedings of the 56th Annual ACM Symposium on Theory of Computing. 2024.
